{
 "metadata": {
  "name": "",
  "signature": "sha256:d55ff8d942784df343029ae6f49b2e37a77b748ee4589bb19ccf2a7290907475"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''Run a computer simulation for flipping 1,000 virtual fair coins. Flip each coin independently 10 \n",
      "times. Focus on 3 coins as follows: c1 is the first coin flipped, crand is a coin chosen randomly \n",
      "from the 1,000, and cmin is the coin which had the minimum frequency of heads (pick the earlier one \n",
      "in case of a tie). Let \u03bd1, \u03bdrand, and \u03bdmin be the fraction of heads obtained for the 3 respective \n",
      "coins out of the 10 tosses.\n",
      "\n",
      "Run the experiment 100,000 times in order to get a full distribution of \u03bd1, \u03bdrand, and \u03bdmin \n",
      "(note that crand and cmin will change from run to run).\n",
      "1. The average value of \u03bdmin is closest to:\n",
      "[a] 0 [b] 0.01\n",
      "[c] 0.1 [d] 0.5\n",
      "[e] 0.67\n",
      "2. Which coin(s) has a distribution of \u03bd that satisfies Hoeffding\u2019s Inequality?\n",
      "[a] c1 only [b] crand only\n",
      "[c] cmin only [d] c1 and crand\n",
      "[e] cmin and crand'''\n",
      "print (\"Homework Week 2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Homework Week 2\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question 1\n",
      "\n",
      "import random\n",
      "import itertools\n",
      "import numpy as np\n",
      "from numba import jit, vectorize\n",
      "import numexpr as ne\n",
      "import random\n",
      "import pylab as plt\n",
      "%pylab inline\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['vectorize', 'random']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 564
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (\"Answers: \")\n",
      "print (\"Question 1 => 0.01 = Option b\")\n",
      "print (\"Question 2 => c1 and crand = Option d\")\n",
      "print (\"Question 3 => mu = Option a\")\n",
      "print (\"Question 4 => 1 = Option d\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Answers: \n",
        "Question 1 = 0.01 = Option b\n",
        "Question 2 = c1 and crand = Option d\n"
       ]
      }
     ],
     "prompt_number": 581
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def q1(numIterations, coins, flips):\n",
      "    f_flips = float(flips)\n",
      "    placeholder = np.zeros((numIterations,3)) # 100 iterations - 3 fixed values\n",
      "\n",
      "    for i in range(numIterations):\n",
      "        x = np.random.randint(2, size=(coins,flips))\n",
      "        x2 = np.sum(x, axis=1)/f_flips\n",
      "        result = np.array([x2[0], np.random.choice(x2), np.min(x2)]) # c1, crand, cmin\n",
      "        placeholder[i] = result\n",
      "\n",
      "    return placeholder"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 565
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numIterations = 100000\n",
      "coins = 1000\n",
      "flips = 10\n",
      "result = q1(numIterations, coins, flips)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 566
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(result[:,2])/100000."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 567,
       "text": [
        "0.037455000000000002"
       ]
      }
     ],
     "prompt_number": 567
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pl = plt.hist(result[:,1], 50, normed=1, facecolor='green', alpha=0.75)\n",
      "plt.show(pl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEACAYAAABBDJb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x11179a610>"
       ]
      }
     ],
     "prompt_number": 580
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (\"These sections are for Questions 5,6,7\")\n",
      "print (\"They were done using R\")\n",
      "\n",
      "\n",
      "# Everything below this line is the content of the file that we will source\n",
      "\n",
      "# File: hw1_hw2_source.R\n",
      "\n",
      "## Function to generate the data (by Chaoping)\n",
      "data.generate = function(n = 10, ext = 1){ \n",
      "  # Generate the points.\n",
      "  x1 = runif(n, -ext, ext)\n",
      "  x2 = runif(n, -ext, ext)\n",
      "  \n",
      "  # Draw a random line in the area.\n",
      "  point = runif(2, -ext, ext)\n",
      "  point2 = runif(2, -ext, ext)\n",
      "  slope = (point2[2] - point[2]) / (point2[1] - point[1])\n",
      "  intercept = point[2] - slope * point[1]\n",
      "  \n",
      "  # Assign the dependent values.\n",
      "  y = as.numeric(x1 * slope + intercept > x2) * 2 - 1\n",
      "  \n",
      "  # Return the values.\n",
      "  data = data.frame(x1,x2,y)\n",
      "  return(list(data = data,slope = slope, intercept = intercept))\n",
      "}  \n",
      "\n",
      "\n",
      "##### PLA  #####\n",
      "\n",
      "# Help function to generate the test points (I used 10000 test points)\n",
      "\n",
      "data.gen2 <- function(n=10000){\n",
      "  x1 = runif(n, -1, 1)\n",
      "  x2 = runif(n, -1, 1)\n",
      "  data <- data.frame(x1,x2)\n",
      "  data\n",
      "}\n",
      "\n",
      "\n",
      "iterations <- numeric(0)    # initialising the iterations and misclassification probability vectors\n",
      "probability <- numeric(0)\n",
      "\n",
      "# Setting up the runs and the algorithm\n",
      "\n",
      "for (i in 1:10){\n",
      "  generated  <-  data.generate(n=10)    # generating points (set n=10 or n=100) and target function\n",
      "  input  <-  as.matrix(cbind(1, generated$data[c(1,2)])) # creating the input matrix\n",
      "  \n",
      "  w  <-  c(0,0,0)  # initializing the weights\n",
      "  res <- apply(input,1,function(x) t(w)%*%x)  # multiplying transpose of w with each row of input matrix \n",
      "  \n",
      "  k <- 1  # initializing the iterations\n",
      "  \n",
      "  while (any(sign(res)!=generated$data$y))    # as long as the sign of all elements of res vector differ from the true \n",
      "  {                                           # output y, we perform the PLA algorithm below\n",
      "    #cat(\"Iteration:\", k, \"\\n\")\n",
      "    mis <- which(sign(res)!=generated$data$y)  # getting the points for which hypotesis is wrong\n",
      "    ifelse (length(mis)==1, n <- mis, n <- sample(which(sign(res)!=generated$data$y),1))  # randomly sample one of these points\n",
      "    w <- w + generated$data$y[n]*input[n,]  # apply PLA, get new weights\n",
      "    res <- apply(input,1,function(x) t(w)%*%x)  # use new weights to get the new res vector\n",
      "    k <- k+1  # increase the iteration count\n",
      "  }\n",
      "  cat (\"Number of iterations to converge: \", k, \"\\n\")\n",
      "  iterations[i] <- k-1 # store the number of iterations needed in each run\n",
      "  \n",
      "  new.data <- data.gen2()  #  generating the test points for examining out-of-sample performance\n",
      "  f  <-  as.numeric(new.data$x1 * generated$slope + generated$intercept > new.data$x2) * 2 - 1  # classifying points according to the true function f\n",
      "  g  <-  as.numeric(new.data$x1 * (-w[2]/w[3]) - w[1]/w[3] > new.data$x2) * 2 - 1  # classifying points according to the hypothesised function g, using the \n",
      "  # final weights provided by PLA            \n",
      "  \n",
      "  probability[i] <- sum(f!=g)/10000  # store the misclassification errors from each run\n",
      "}\n",
      "\n",
      "# Main results: average of iterations and estimated misclassification probability\n",
      "mean(iterations)\n",
      "mean(probability)\n",
      "\n",
      "\n",
      "# Function to plot the points and f and g functions from  one iteration\n",
      "\n",
      "library(ggplot2)\n",
      "\n",
      "qplot(x1,x2,col= as.factor(y), data = generated$data) + \n",
      "  geom_abline(intercept = generated$intercept, slope = generated$slope) +\n",
      "  geom_abline(intercept = -w[1]/w[3], slope = -w[2]/w[3], col=3)\n",
      "\n",
      "# qplot(x1,x2,col= as.factor(y), data = generated$data) + \n",
      "#   geom_abline(intercept = generated$intercept, slope = generated$slope)\n",
      "\n",
      "\n",
      "#g  <-  as.numeric(new.data$x1 * (-w[2]/w[3]) - w[1]/w[3] > new.data$x2) * 2 - 1  # classifying points according to the hypothesised function g, using the \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "source(\"hw1_hw2_source.R\")\n",
      "num_pts = 100\n",
      "num_iterations = 1000\n",
      "e_in = 0\n",
      "generated = data.generate(n=num_pts)\n",
      "\n",
      "\n",
      "for (i in 1:num_iterations) {\n",
      "  generated = data.generate(n=num_pts)\n",
      "  \n",
      "  new_mat = as.matrix(cbind(x0=1, generated$data[,1:2]))\n",
      "  \n",
      "  mat_inv = solve((t(new_mat) %*% new_mat)) %*% t(new_mat)\n",
      "  \n",
      "  w = mat_inv %*% generated$data[,3]\n",
      "  h_y = as.vector(sign(t(w) %*% as.matrix(t(as.matrix(new_mat)))))\n",
      "  \n",
      "  e_in = e_in + sum(generated$data$y != h_y) / num_pts\n",
      "  \n",
      "}\n",
      "\n",
      "average_e_in = e_in / num_iterations\n",
      "\n",
      "probability <- numeric(0)\n",
      "\n",
      "test_points = 1000\n",
      "\n",
      "for (k in 1:num_iterations){\n",
      "new.data <- data.gen2(n = test_points)  #  generating the test points for examining out-of-sample performance\n",
      "f  <-  as.numeric(new.data$x1 * generated$slope + generated$intercept > new.data$x2) * 2 - 1  # classifying points according to the true function f\n",
      "g  <-  as.numeric(new.data$x1 * (-w[2]/w[3]) - w[1]/w[3] > new.data$x2) * 2 - 1  # classifying points according to the hypothesised function g, using the \n",
      "# final weights provided by PLA            \n",
      "\n",
      "probability[k] <- sum(f!=g)/test_points  # store the misclassification errors from each run\n",
      "}\n",
      "\n",
      "cat (\"Answer 5: Average e_in is\", average_e_in, \"and average e_out is\", mean(probability))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "source(\"hw1_hw2_source.R\")\n",
      "\n",
      "num_pts = 10\n",
      "# Setting up the runs and the algorithm\n",
      "\n",
      "for (i in 1:1000){\n",
      "  generated = data.generate(n=num_pts)\n",
      "  \n",
      "  # Use linear regression to find w\n",
      "  new_mat = as.matrix(cbind(x0=1, generated$data[,1:2]))  \n",
      "  mat_inv = solve((t(new_mat) %*% new_mat)) %*% t(new_mat)\n",
      "  w = mat_inv %*% generated$data[,3] # Weights initialized\n",
      "  \n",
      "  #w <- c(0,0,0)\n",
      "  \n",
      "  # Back to PLA\n",
      "  input  <-  as.matrix(cbind(1, generated$data[c(1,2)])) # creating the input matrix\n",
      "  res <- apply(input,1,function(x) t(w)%*%x)  # multiplying transpose of w with each row of input matrix \n",
      "  \n",
      "  k <- 1  # initializing the iterations\n",
      "  \n",
      "  while (any(sign(res)!=generated$data$y))    # as long as the sign of all elements of res vector differ from the true \n",
      "  {                                           # output y, we perform the PLA algorithm below\n",
      "    #cat(\"Iteration:\", k, \"\\n\")\n",
      "    mis <- which(sign(res)!=generated$data$y)  # getting the points for which hypotesis is wrong\n",
      "    ifelse (length(mis)==1, n <- mis, n <- sample(which(sign(res)!=generated$data$y),1))  # randomly sample one of these points\n",
      "    w <- w + generated$data$y[n]*input[n,]  # apply PLA, get new weights\n",
      "    res <- apply(input,1,function(x) t(w)%*%x)  # use new weights to get the new res vector\n",
      "    k <- k+1  # increase the iteration count\n",
      "  }\n",
      "  cat (\"Number of iterations to converge: \", k, \"\\n\")\n",
      "  iterations[i] <- k-1 # store the number of iterations needed in each run\n",
      "}\n",
      "\n",
      "# Main results: average of iterations required to converge\n",
      "mean(iterations)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
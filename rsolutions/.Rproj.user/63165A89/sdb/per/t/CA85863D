{
    "contents" : "## Function to generate the data (by Chaoping)\ndata.generate = function(n = 10, ext = 1){ \n  # Generate the points.\n  x1 = runif(n, -ext, ext)\n  x2 = runif(n, -ext, ext)\n  \n  # Draw a random line in the area.\n  point = runif(2, -ext, ext)\n  point2 = runif(2, -ext, ext)\n  slope = (point2[2] - point[2]) / (point2[1] - point[1])\n  intercept = point[2] - slope * point[1]\n  \n  # Assign the dependent values.\n  y = as.numeric(x1 * slope + intercept > x2) * 2 - 1\n  \n  # Return the values.\n  data = data.frame(x1,x2,y)\n  return(list(data = data,slope = slope, intercept = intercept))\n}  \n\n\n##### PLA  #####\n\n# Help function to generate the test points (I used 10000 test points)\n\ndata.gen2 <- function(n=10000){\n  x1 = runif(n, -1, 1)\n  x2 = runif(n, -1, 1)\n  data <- data.frame(x1,x2)\n  data\n}\n\n\niterations <- numeric(0)    # initialising the iterations and misclassification probability vectors\nprobability <- numeric(0)\n\n# Setting up the runs and the algorithm\n\nfor (i in 1:2){\n  generated  <-  data.generate(n=10)    # generating points (set n=10 or n=100) and target function\n  input  <-  as.matrix(cbind(1, generated$data[c(1,2)])) # creating the input matrix\n  \n  w  <-  c(0,0,0)  # initializing the weights\n  res <- apply(input,1,function(x) t(w)%*%x)  # multiplying transpose of w with each row of input matrix \n  \n  k <- 1  # initializing the iterations\n  \n  while (any(sign(res)!=generated$data$y))    # as long as the sign of all elements of res vector differ from the true \n  {                                           # output y, we perform the PLA algorithm below\n    #cat(\"Iteration:\", k, \"\\n\")\n    mis <- which(sign(res)!=generated$data$y)  # getting the points for which hypotesis is wrong\n    ifelse (length(mis)==1, n <- mis, n <- sample(which(sign(res)!=generated$data$y),1))  # randomly sample one of these points\n    w <- w + generated$data$y[n]*input[n,]  # apply PLA, get new weights\n    res <- apply(input,1,function(x) t(w)%*%x)  # use new weights to get the new res vector\n    k <- k+1  # increase the iteration count\n  }\n  #cat (\"Number of iterations to converge: \", k, \"\\n\")\n  iterations[i] <- k-1 # store the number of iterations needed in each run\n  \n  new.data <- data.gen2()  #  generating the test points for examining out-of-sample performance\n  f  <-  as.numeric(new.data$x1 * generated$slope + generated$intercept > new.data$x2) * 2 - 1  # classifying points according to the true function f\n  g  <-  as.numeric(new.data$x1 * (-w[2]/w[3]) - w[1]/w[3] > new.data$x2) * 2 - 1  # classifying points according to the hypothesised function g, using the \n  # final weights provided by PLA            \n  \n  probability[i] <- sum(f!=g)/10000  # store the misclassification errors from each run\n}\n\n# Main results: average of iterations and estimated misclassification probability\nmean(iterations)\nmean(probability)\n\n\n# Function to plot the points and f and g functions from  one iteration\n\nlibrary(ggplot2)\n\nqplot(x1,x2,col= as.factor(y), data = generated$data) + \n  geom_abline(intercept = generated$intercept, slope = generated$slope) +\n  geom_abline(intercept = -w[1]/w[3], slope = -w[2]/w[3], col=3)\n\n# qplot(x1,x2,col= as.factor(y), data = generated$data) + \n#   geom_abline(intercept = generated$intercept, slope = generated$slope)\n\n\n#g  <-  as.numeric(new.data$x1 * (-w[2]/w[3]) - w[1]/w[3] > new.data$x2) * 2 - 1  # classifying points according to the hypothesised function g, using the \n\n\n\n",
    "created" : 1413141106977.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "732050207",
    "id" : "CA85863D",
    "lastKnownWriteTime" : 1413146767,
    "path" : "~/Documents/study/edX/cs1156x/rsolutions/hw1_hw2_source.R",
    "project_path" : "hw1_hw2_source.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}